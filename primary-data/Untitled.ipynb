{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Interactive Beam requires Python 3.5.3+.\n",
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.internal.gcp.auth:Setting socket default timeout to 60 seconds.\n",
      "INFO:apache_beam.internal.gcp.auth:socket default timeout is 60.0 seconds.\n",
      "INFO:oauth2client.transport:Attempting refresh to obtain initial access_token\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'acs_2018_modeled'\n",
      " projectId: 'sashimi-266523'\n",
      " tableId: 'Built_Year'> referenced by query SELECT NAME, DP04_0017PE, DP04_0018PE, DP04_0019PE, DP04_0020PE, DP04_0021PE, DP04_0022PE,      DP04_0023PE, DP04_0024PE, DP04_0025PE, DP04_0026PE FROM acs_2018_modeled.Built_Year limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sashimi-266523:temp_dataset_b0f49f7eaf4248f6a876a4afb25d6944 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sashimi-266523.acs_2018_modeled.Built_Year_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'NAME'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_2014_or_later'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_2010_to_2013'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_2000_to_2009'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1990_to_1999'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1980_to_1989'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1970_to_1979'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1960_to_1969'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1950_to_1959'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1940_to_1949'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1939_or_before'\n",
      " type: 'FLOAT'>]>. Result: <Table\n",
      " creationTime: 1583623989056\n",
      " etag: '9rbS2xCWBsHgTPxUoPJXcA=='\n",
      " id: 'sashimi-266523:acs_2018_modeled.Built_Year_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583623989092\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'NAME'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_2014_or_later'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_2010_to_2013'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_2000_to_2009'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1990_to_1999'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1980_to_1989'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1970_to_1979'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1960_to_1969'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1950_to_1959'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1940_to_1949'\n",
      " type: 'FLOAT'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Built_1939_or_before'\n",
      " type: 'FLOAT'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sashimi-266523/datasets/acs_2018_modeled/tables/Built_Year_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'acs_2018_modeled'\n",
      " projectId: 'sashimi-266523'\n",
      " tableId: 'Built_Year_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.11 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run Built_Year_beam.py "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.options.pipeline_options:--region not set; will default to us-central1. Future releases of Beam will require the user to set --region explicitly, or else have a default set via the gcloud tool. https://cloud.google.com/compute/docs/regions-zones\n",
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/runners/dataflow/dataflow_runner.py:740: BeamDeprecationWarning: BigQuerySink is deprecated since 2.11.0. Use WriteToBigQuery instead.\n",
      "  kms_key=transform.kms_key))\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/pipeline.pb...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/pipeline.pb in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading source distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpta7v1vsg', 'apache-beam==2.19.0', '--no-deps', '--no-binary', ':all:']\n",
      "INFO:apache_beam.runners.portability.stager:Staging SDK sources from PyPI to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/dataflow_python_sdk.tar\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/dataflow_python_sdk.tar...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/dataflow_python_sdk.tar in 0 seconds.\n",
      "INFO:apache_beam.runners.portability.stager:Downloading binary distribution of the SDK from PyPi\n",
      "INFO:apache_beam.runners.portability.stager:Executing command: ['/home/jupyter/venv/bin/python', '-m', 'pip', 'download', '--dest', '/tmp/tmpta7v1vsg', 'apache-beam==2.19.0', '--no-deps', '--only-binary', ':all:', '--python-version', '35', '--implementation', 'cp', '--abi', 'cp35m', '--platform', 'manylinux1_x86_64']\n",
      "INFO:apache_beam.runners.portability.stager:Staging binary distribution of the SDK from PyPI to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Starting GCS upload to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl...\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Completed GCS upload to gs://sashimi-sushi/staging/built-year-df.1583626620.628000/apache_beam-2.19.0-cp35-cp35m-manylinux1_x86_64.whl in 1 seconds.\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Create job: <Job\n",
      " createTime: '2020-03-08T00:17:06.365079Z'\n",
      " currentStateTime: '1970-01-01T00:00:00Z'\n",
      " id: '2020-03-07_16_17_05-17059109976186217101'\n",
      " location: 'us-central1'\n",
      " name: 'built-year-df'\n",
      " projectId: 'sashimi-266523'\n",
      " stageStates: []\n",
      " startTime: '2020-03-08T00:17:06.365079Z'\n",
      " steps: []\n",
      " tempFiles: []\n",
      " type: TypeValueValuesEnum(JOB_TYPE_BATCH, 1)>\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:Created job with id: [2020-03-07_16_17_05-17059109976186217101]\n",
      "INFO:apache_beam.runners.dataflow.internal.apiclient:To access the Dataflow monitoring console, please navigate to https://console.cloud.google.com/dataflow/jobsDetail/locations/us-central1/jobs/2020-03-07_16_17_05-17059109976186217101?project=sashimi-266523\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-07_16_17_05-17059109976186217101 is in state JOB_STATE_PENDING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:05.268Z: JOB_MESSAGE_DETAILED: Autoscaling was automatically enabled for job 2020-03-07_16_17_05-17059109976186217101.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:05.268Z: JOB_MESSAGE_DETAILED: Autoscaling is enabled for job 2020-03-07_16_17_05-17059109976186217101. The number of workers will be between 1 and 1000.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:10.883Z: JOB_MESSAGE_DETAILED: Checking permissions granted to controller Service Account.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:11.989Z: JOB_MESSAGE_BASIC: Worker configuration: n1-standard-1 in us-central1-c.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:12.669Z: JOB_MESSAGE_DETAILED: Expanding CoGroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:12.719Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Record the classified data/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:12.772Z: JOB_MESSAGE_DEBUG: Combiner lifting skipped for step Record original data/Write/WriteImpl/GroupByKey: GroupByKey not followed by a combiner.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:12.835Z: JOB_MESSAGE_DETAILED: Expanding GroupByKey operations into optimizable parts.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:12.872Z: JOB_MESSAGE_DETAILED: Lifting ValueCombiningMappingFns into MergeBucketsMappingFns\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.004Z: JOB_MESSAGE_DEBUG: Annotating graph with Autotuner information.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.322Z: JOB_MESSAGE_DETAILED: Fusing adjacent ParDo, Read, Write, and Flatten operations\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.391Z: JOB_MESSAGE_DETAILED: Fusing consumer Format column into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.433Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/WriteBundles/WriteBundles into Read from BigQuery\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.473Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/WriteBundles/WriteBundles into Format column\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.516Z: JOB_MESSAGE_DETAILED: Fusing consumer Write BQ table/WriteToBigQuery/NativeWrite into Format column\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.552Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/Pair into Record original data/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.593Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/WindowInto(WindowIntoFn) into Record original data/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.635Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/GroupByKey/Reify into Record original data/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.667Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/GroupByKey/Write into Record original data/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.701Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/GroupByKey/GroupByWindow into Record original data/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.742Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/Extract into Record original data/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.788Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/Pair into Record the classified data/Write/WriteImpl/WriteBundles/WriteBundles\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.829Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/WindowInto(WindowIntoFn) into Record the classified data/Write/WriteImpl/Pair\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.874Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/GroupByKey/Reify into Record the classified data/Write/WriteImpl/WindowInto(WindowIntoFn)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.919Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/GroupByKey/Write into Record the classified data/Write/WriteImpl/GroupByKey/Reify\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:13.965Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/GroupByKey/GroupByWindow into Record the classified data/Write/WriteImpl/GroupByKey/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.018Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/Extract into Record the classified data/Write/WriteImpl/GroupByKey/GroupByWindow\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.054Z: JOB_MESSAGE_DETAILED: Fusing consumer Record original data/Write/WriteImpl/InitializeWrite into Record original data/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.104Z: JOB_MESSAGE_DETAILED: Fusing consumer Record the classified data/Write/WriteImpl/InitializeWrite into Record the classified data/Write/WriteImpl/DoOnce/Read\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.156Z: JOB_MESSAGE_DEBUG: Workflow config is missing a default resource spec.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.198Z: JOB_MESSAGE_DEBUG: Adding StepResource setup and teardown to workflow graph.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.243Z: JOB_MESSAGE_DEBUG: Adding workflow start and stop steps.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.282Z: JOB_MESSAGE_DEBUG: Assigning stage ids.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.490Z: JOB_MESSAGE_DEBUG: Executing wait step start29\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.573Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/DoOnce/Read+Record the classified data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.618Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/DoOnce/Read+Record original data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.630Z: JOB_MESSAGE_DEBUG: Starting worker pool setup.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.657Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.670Z: JOB_MESSAGE_BASIC: Starting 1 workers in us-central1-c...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.695Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.746Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.773Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/GroupByKey/Create\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.853Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:14.967Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/GroupByKey/Session\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-07_16_17_05-17059109976186217101 is in state JOB_STATE_RUNNING\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:17:39.012Z: JOB_MESSAGE_DETAILED: Autoscaling: Raised the number of workers to 1 based on the rate of progress in the currently running step(s).\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:19:32.913Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:19:32.973Z: JOB_MESSAGE_DETAILED: Workers have started successfully.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.276Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/DoOnce/Read+Record original data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.373Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.406Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.475Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.509Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.564Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.673Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.698Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:14.754Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:15.043Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:15.152Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:15.233Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:17.913Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/DoOnce/Read+Record the classified data/Write/WriteImpl/InitializeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:17.984Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/DoOnce/Read.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.015Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/InitializeWrite.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.080Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.112Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.133Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.139Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.169Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.225Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.232Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/WriteBundles/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.343Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/FinalizeWrite/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.392Z: JOB_MESSAGE_BASIC: Executing operation Read from BigQuery+Format column+Record original data/Write/WriteImpl/WriteBundles/WriteBundles+Record the classified data/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Record original data/Write/WriteImpl/Pair+Record original data/Write/WriteImpl/WindowInto(WindowIntoFn)+Record original data/Write/WriteImpl/GroupByKey/Reify+Record original data/Write/WriteImpl/GroupByKey/Write+Record the classified data/Write/WriteImpl/Pair+Record the classified data/Write/WriteImpl/WindowInto(WindowIntoFn)+Record the classified data/Write/WriteImpl/GroupByKey/Reify+Record the classified data/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:18.446Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/PreFinalize/AsSingleton(InitializeWrite.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:20:19.452Z: JOB_MESSAGE_BASIC: BigQuery query issued as job: \"dataflow_job_13585122166412935786\". You can check its status with the bq tool: \"bq show -j --project_id=sashimi-266523 dataflow_job_13585122166412935786\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:21:26.281Z: JOB_MESSAGE_BASIC: BigQuery query completed, job : \"dataflow_job_13585122166412935786\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:21:26.883Z: JOB_MESSAGE_BASIC: BigQuery export job \"dataflow_job_8304701369098272927\" started. You can check its status with the bq tool: \"bq show -j --project_id=sashimi-266523 dataflow_job_8304701369098272927\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:21:57.253Z: JOB_MESSAGE_DETAILED: BigQuery export job progress: \"dataflow_job_8304701369098272927\" observed total of 1 exported files thus far.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:21:57.284Z: JOB_MESSAGE_BASIC: BigQuery export job finished: \"dataflow_job_8304701369098272927\"\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:01.743Z: JOB_MESSAGE_BASIC: Executing BigQuery import job \"dataflow_job_13585122166412937990\". You can check its status with the bq tool: \"bq show -j --project_id=sashimi-266523 dataflow_job_13585122166412937990\".\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:12.580Z: JOB_MESSAGE_BASIC: BigQuery import job \"dataflow_job_13585122166412937990\" done.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:13.244Z: JOB_MESSAGE_BASIC: Finished operation Read from BigQuery+Format column+Record original data/Write/WriteImpl/WriteBundles/WriteBundles+Record the classified data/Write/WriteImpl/WriteBundles/WriteBundles+Write BQ table/WriteToBigQuery/NativeWrite+Record original data/Write/WriteImpl/Pair+Record original data/Write/WriteImpl/WindowInto(WindowIntoFn)+Record original data/Write/WriteImpl/GroupByKey/Reify+Record original data/Write/WriteImpl/GroupByKey/Write+Record the classified data/Write/WriteImpl/Pair+Record the classified data/Write/WriteImpl/WindowInto(WindowIntoFn)+Record the classified data/Write/WriteImpl/GroupByKey/Reify+Record the classified data/Write/WriteImpl/GroupByKey/Write\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:13.335Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:13.367Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:13.384Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:13.452Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/GroupByKey/Read+Record the classified data/Write/WriteImpl/GroupByKey/GroupByWindow+Record the classified data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:13.458Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/GroupByKey/Close\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:13.536Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/GroupByKey/Read+Record original data/Write/WriteImpl/GroupByKey/GroupByWindow+Record original data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.291Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/GroupByKey/Read+Record original data/Write/WriteImpl/GroupByKey/GroupByWindow+Record original data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.346Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.404Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.428Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.461Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.469Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.509Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.531Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:26.585Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:31.387Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:31.456Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:31.521Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:31.582Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:31.656Z: JOB_MESSAGE_DEBUG: Value \"Record original data/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:31.717Z: JOB_MESSAGE_BASIC: Executing operation Record original data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.018Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/GroupByKey/Read+Record the classified data/Write/WriteImpl/GroupByKey/GroupByWindow+Record the classified data/Write/WriteImpl/Extract\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.089Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/Extract.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.169Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.207Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.236Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.266Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.319Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/FinalizeWrite/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.353Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/PreFinalize/AsIter(Extract.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:34.436Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:38.054Z: JOB_MESSAGE_BASIC: Finished operation Record original data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:41.355Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/PreFinalize/PreFinalize\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:41.422Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/PreFinalize.out\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:41.533Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:41.642Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:41.770Z: JOB_MESSAGE_DEBUG: Value \"Record the classified data/Write/WriteImpl/FinalizeWrite/AsSingleton(PreFinalize.out.0).output\" materialized.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:41.861Z: JOB_MESSAGE_BASIC: Executing operation Record the classified data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:45.438Z: JOB_MESSAGE_BASIC: Finished operation Record the classified data/Write/WriteImpl/FinalizeWrite/FinalizeWrite\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:45.639Z: JOB_MESSAGE_DEBUG: Executing success step success27\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:45.921Z: JOB_MESSAGE_DETAILED: Cleaning up.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:45.983Z: JOB_MESSAGE_DEBUG: Starting worker pool teardown.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:22:46.020Z: JOB_MESSAGE_BASIC: Stopping worker pool...\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 2/2)\n",
      "INFO:oauth2client.transport:Refreshing due to a 401 (attempt 1/2)\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:25:12.733Z: JOB_MESSAGE_DETAILED: Autoscaling: Resized worker pool from 1 to 0.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:25:12.774Z: JOB_MESSAGE_BASIC: Worker pool stopped.\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:2020-03-08T00:25:12.807Z: JOB_MESSAGE_DEBUG: Tearing down pending resources...\n",
      "INFO:apache_beam.runners.dataflow.dataflow_runner:Job 2020-03-07_16_17_05-17059109976186217101 is in state JOB_STATE_DONE\n"
     ]
    }
   ],
   "source": [
    "%run Built_Year_dataflow.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'acs_2018_modeled'\n",
      " projectId: 'sashimi-266523'\n",
      " tableId: 'General_School_Enrollment'> referenced by query SELECT NAME, S1401_C01_004E, S1401_C01_005E, S1401_C01_006E, S1401_C01_007E, S1401_C01_008E, S1401_C01_009E FROM acs_2018_modeled.General_School_Enrollment limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sashimi-266523:temp_dataset_3036904f657444368c88429222f2f3b1 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sashimi-266523.acs_2018_modeled.General_School_Enrollment_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'NAME'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Kindergarden'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grade1_to_4'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grade5_to_8'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grade9_to_12'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'College_Undergrad'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grad_HigherEdu'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583624263161\n",
      " etag: 'NuOl6EJPsWk5SuweCZ1qKA=='\n",
      " id: 'sashimi-266523:acs_2018_modeled.General_School_Enrollment_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583624263197\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'NAME'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Kindergarden'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grade1_to_4'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grade5_to_8'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grade9_to_12'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'College_Undergrad'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grad_HigherEdu'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sashimi-266523/datasets/acs_2018_modeled/tables/General_School_Enrollment_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'acs_2018_modeled'\n",
      " projectId: 'sashimi-266523'\n",
      " tableId: 'General_School_Enrollment_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "%run General_School_Enrollment_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter/venv/lib/python3.5/site-packages/apache_beam/io/gcp/bigquery.py:1421: BeamDeprecationWarning: options is deprecated since First stable release. References to <pipeline>.options will not be supported\n",
      "  experiments = p.options.view_as(DebugOptions).experiments or []\n",
      "INFO:apache_beam.runners.direct.direct_runner:Running pipeline with DirectRunner.\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Using location 'US' from table <TableReference\n",
      " datasetId: 'acs_2018_modeled'\n",
      " projectId: 'sashimi-266523'\n",
      " tableId: 'PrivatePublic_School_Enrollment'> referenced by query SELECT NAME, S1401_C03_008E, S1401_C05_008E, S1401_C03_009E, S1401_C05_009E FROM acs_2018_modeled.PrivatePublic_School_Enrollment limit 50\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Dataset sashimi-266523:temp_dataset_35b27913b9fb47cc9ff75b21d796d600 does not exist so we will create it as temporary with location=US\n",
      "INFO:apache_beam.io.gcp.bigquery_tools:Created table sashimi-266523.acs_2018_modeled.PrivatePublic_School_Enrollment_Beam with schema <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'NAME'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'College_Undergrad_Public'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'College_Undergrad_Private'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grad_HigherEdu_Public'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grad_HigherEdu_Private'\n",
      " type: 'INTEGER'>]>. Result: <Table\n",
      " creationTime: 1583624467982\n",
      " etag: '+mtVwW1EyQcZnVUz8YNCoQ=='\n",
      " id: 'sashimi-266523:acs_2018_modeled.PrivatePublic_School_Enrollment_Beam'\n",
      " kind: 'bigquery#table'\n",
      " lastModifiedTime: 1583624468017\n",
      " location: 'US'\n",
      " numBytes: 0\n",
      " numLongTermBytes: 0\n",
      " numRows: 0\n",
      " schema: <TableSchema\n",
      " fields: [<TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'NAME'\n",
      " type: 'STRING'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'College_Undergrad_Public'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'College_Undergrad_Private'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grad_HigherEdu_Public'\n",
      " type: 'INTEGER'>, <TableFieldSchema\n",
      " fields: []\n",
      " mode: 'NULLABLE'\n",
      " name: 'Grad_HigherEdu_Private'\n",
      " type: 'INTEGER'>]>\n",
      " selfLink: 'https://www.googleapis.com/bigquery/v2/projects/sashimi-266523/datasets/acs_2018_modeled/tables/PrivatePublic_School_Enrollment_Beam'\n",
      " tableReference: <TableReference\n",
      " datasetId: 'acs_2018_modeled'\n",
      " projectId: 'sashimi-266523'\n",
      " tableId: 'PrivatePublic_School_Enrollment_Beam'>\n",
      " type: 'TABLE'>.\n",
      "WARNING:apache_beam.io.gcp.bigquery_tools:Sleeping for 150 seconds before the write as BigQuery inserts can be routed to deleted table for 2 mins after the delete and create.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n",
      "INFO:apache_beam.io.filebasedsink:Starting finalize_write threads with num_shards: 1 (skipped: 0), batches: 1, num_threads: 1\n",
      "INFO:apache_beam.io.filebasedsink:Renamed 1 shards in 0.10 seconds.\n"
     ]
    }
   ],
   "source": [
    "% run PrivatePublic_School_Enrollment_beam.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (beam_venv)",
   "language": "python",
   "name": "beam_venv_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
